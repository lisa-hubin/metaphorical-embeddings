{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ad1d3f10",
      "metadata": {
        "id": "ad1d3f10"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/Lisa/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n",
            "/Users/Lisa/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "from textwrap import wrap\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "import matplotlib.cm as cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "300d7e27",
      "metadata": {
        "id": "300d7e27"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at GroNLP/bert-base-dutch-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/bert-base-dutch-cased\")\n",
        "model = AutoModel.from_pretrained(\"GroNLP/bert-base-dutch-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2300e8cf",
      "metadata": {
        "id": "2300e8cf"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def encode_sentence_and_extract_position(sentence, position):\n",
        "    ids = tokenizer.encode(sentence)\n",
        "    bert_output = model.forward(torch.tensor(ids).unsqueeze(0),\n",
        "                                encoder_hidden_states = True)\n",
        "    final_layer_embeddings = bert_output['last_hidden_state'].squeeze()\n",
        "    if type(position) == int:\n",
        "        return final_layer_embeddings[position].unsqueeze(0)\n",
        "    elif type(position) == list:\n",
        "        return torch.mean(\n",
        "            final_layer_embeddings[position[0]:position[1]], 0\n",
        "            ).unsqueeze(0)\n",
        "\n",
        "def find_position_word(sentence, word):\n",
        "    ids_word = tokenizer.encode(word)\n",
        "    tokens_word = tokenizer.convert_ids_to_tokens(ids_word)[1:-1]\n",
        "    ids_sentence = tokenizer.encode(sentence)\n",
        "    tokens_sentence = tokenizer.convert_ids_to_tokens(ids_sentence)\n",
        "    if len(tokens_word) == 1:\n",
        "        position_word_in_sentence = tokens_sentence.index(tokens_word[0])\n",
        "    else:\n",
        "        position_word_in_sentence = [tokens_sentence.index(tokens_word[0]),tokens_sentence.index(tokens_word[-1])+1]\n",
        "    return position_word_in_sentence\n",
        "\n",
        "def get_embeddings_from_sentences(word, sentences):\n",
        "    embeddings = []\n",
        "    for index, sentence in sentences.iterrows():\n",
        "        position = find_position_word(sentence['sentence'], word)\n",
        "        embeddings.append(encode_sentence_and_extract_position(sentence['sentence'], position))\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "def extend_df_with_pca(df):\n",
        "    df_new = df.copy()\n",
        "\n",
        "    pca = PCA(n_components=3)\n",
        "    components = pca.fit_transform(matrix_np)\n",
        "\n",
        "    df_new.insert(1, 'x', components[:,0])\n",
        "    df_new.insert(2, 'y', components[:,1])\n",
        "    df_new.insert(3, 'z', components[:,2])\n",
        "\n",
        "    return df_new"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "J5kJINcGGf7c",
      "metadata": {
        "id": "J5kJINcGGf7c"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RCm_WwkfG4Dd",
      "metadata": {
        "id": "RCm_WwkfG4Dd"
      },
      "source": [
        "## Verbs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e3dda2cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_dragen = pd.read_excel('data/data_dragen_net.xlsx')\n",
        "\n",
        "embeddings = get_embeddings_from_sentences('dragen', df_dragen)\n",
        "emb_matrix = torch.cat(embeddings, dim=0)\n",
        "\n",
        "matrix_np = emb_matrix.cpu().detach().numpy()\n",
        "\n",
        "df_pca = extend_df_with_pca(df_dragen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "b87fc824",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_broeden = pd.read_excel('data/data_broeden_net.xlsx')\n",
        "\n",
        "embeddings = get_embeddings_from_sentences('broeden', df_broeden)\n",
        "emb_matrix = torch.cat(embeddings, dim=0)\n",
        "\n",
        "matrix_np = emb_matrix.cpu().detach().numpy()\n",
        "\n",
        "df_pca = extend_df_with_pca(df_broeden)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e1b1561a",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_vechten = pd.read_excel('data/data_vechten_net.xlsx')\n",
        "\n",
        "embeddings = get_embeddings_from_sentences('vechten', df_vechten)\n",
        "emb_matrix = torch.cat(embeddings, dim=0)\n",
        "\n",
        "matrix_np = emb_matrix.cpu().detach().numpy()\n",
        "\n",
        "df_pca = extend_df_with_pca(df_vechten)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e-CvbzZSG2tw",
      "metadata": {
        "id": "e-CvbzZSG2tw"
      },
      "source": [
        "## Nouns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "IIrmr648QkOx",
      "metadata": {
        "id": "IIrmr648QkOx"
      },
      "outputs": [],
      "source": [
        "df_breuk = pd.read_excel('data/data_breuk_net.xlsx')\n",
        "\n",
        "embeddings = get_embeddings_from_sentences('breuk', df_breuk)\n",
        "emb_matrix = torch.cat(embeddings, dim=0)\n",
        "\n",
        "matrix_np = emb_matrix.cpu().detach().numpy()\n",
        "\n",
        "df_pca = extend_df_with_pca(df_breuk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "796d489d",
      "metadata": {
        "id": "796d489d"
      },
      "outputs": [],
      "source": [
        "df_golf = pd.read_excel('data/data_golf_net.xlsx')\n",
        "\n",
        "embeddings = get_embeddings_from_sentences('golf', df_golf)\n",
        "emb_matrix = torch.cat(embeddings, dim=0)\n",
        "\n",
        "matrix_np = emb_matrix.cpu().detach().numpy()\n",
        "\n",
        "df_pca = extend_df_with_pca(df_golf)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "0505b5ce",
      "metadata": {
        "id": "0505b5ce"
      },
      "outputs": [],
      "source": [
        "df_weg = pd.read_excel('data/data_weg_net.xlsx')\n",
        "\n",
        "embeddings = get_embeddings_from_sentences('weg', df_weg)\n",
        "emb_matrix = torch.cat(embeddings, dim=0)\n",
        "\n",
        "matrix_np = emb_matrix.cpu().detach().numpy()\n",
        "\n",
        "df_pca = extend_df_with_pca(df_weg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "fcc25483",
      "metadata": {
        "id": "fcc25483"
      },
      "outputs": [],
      "source": [
        "df_hoofd = pd.read_excel('data/data_hoofd_net.xlsx')\n",
        "\n",
        "embeddings = get_embeddings_from_sentences('hoofd', df_hoofd)\n",
        "emb_matrix = torch.cat(embeddings, dim=0)\n",
        "\n",
        "matrix_np = emb_matrix.cpu().detach().numpy()\n",
        "\n",
        "df_pca = extend_df_with_pca(df_hoofd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "d7c029bd",
      "metadata": {
        "id": "d7c029bd"
      },
      "outputs": [],
      "source": [
        "df_mes = pd.read_excel('data/data_mes_net.xlsx')\n",
        "\n",
        "embeddings = get_embeddings_from_sentences('mes', df_mes)\n",
        "emb_matrix = torch.cat(embeddings, dim=0)\n",
        "\n",
        "matrix_np = emb_matrix.cpu().detach().numpy()\n",
        "\n",
        "df_pca = extend_df_with_pca(df_mes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XPbSpBWOGmsF",
      "metadata": {
        "id": "XPbSpBWOGmsF"
      },
      "source": [
        "# Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AjQ3W-WrSGeP",
      "metadata": {
        "id": "AjQ3W-WrSGeP"
      },
      "outputs": [],
      "source": [
        "#2D\n",
        "fig = px.scatter(df_pca, x='x', y='y', color='M/L',\n",
        "                 color_discrete_map={'M': 'red', 'L': 'blue'},\n",
        "                 hover_data='sentence')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H8umFNHlSUJj",
      "metadata": {
        "id": "H8umFNHlSUJj"
      },
      "outputs": [],
      "source": [
        "#3D\n",
        "fig = px.scatter_3d(\n",
        "    df_pca, x='x', y='y', z='z', color='M/L',\n",
        "    color_discrete_map={'M': 'red', 'L': 'blue'},\n",
        "    hover_data='sentence'\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ZTZCtENI1HmX",
      "metadata": {
        "id": "ZTZCtENI1HmX"
      },
      "outputs": [],
      "source": [
        "df = df_dragen"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4faa2a43",
      "metadata": {},
      "source": [
        "## Two clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "geiTT25SWUhF",
      "metadata": {
        "id": "geiTT25SWUhF"
      },
      "outputs": [],
      "source": [
        "best_cluster = None\n",
        "best_score = -np.inf\n",
        "\n",
        "for random_state in range(1, 51):\n",
        "    kmeans = KMeans(n_clusters=2, n_init=\"auto\", random_state=random_state)\n",
        "    cluster = kmeans.fit(matrix_np)\n",
        "    score = cluster.score(matrix_np)\n",
        "    \n",
        "    if score > best_score:\n",
        "        best_cluster = cluster\n",
        "        best_score = score\n",
        "        best_random_state = random_state\n",
        "\n",
        "kmeans = KMeans(n_clusters=2, n_init=\"auto\", random_state=best_random_state)\n",
        "aggl_ward = AgglomerativeClustering(n_clusters=2)\n",
        "aggl_complete = AgglomerativeClustering(n_clusters=2, linkage=\"complete\")\n",
        "aggl_average = AgglomerativeClustering(n_clusters=2, linkage=\"average\")\n",
        "aggl_single = AgglomerativeClustering(n_clusters=2, linkage=\"single\")\n",
        "\n",
        "\n",
        "clusters = [kmeans, aggl_ward, aggl_complete, aggl_average, aggl_single]\n",
        "\n",
        "for cluster in clusters:\n",
        "  cluster = cluster.fit(matrix_np)\n",
        "  df[cluster] = cluster.labels_\n",
        "  df_pca[cluster] = cluster.labels_\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "139cb6aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "#visualisation\n",
        "fig = px.scatter(df_pca, x='x', y='y', color='M/L',\n",
        "                 color_discrete_map={'M': 'red', 'L': 'blue'},\n",
        "                 symbol= kmeans,\n",
        "                 hover_data='sentence')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fab6b6e",
      "metadata": {},
      "outputs": [],
      "source": [
        "#evaluation\n",
        "df['M/L'] = df['M/L'].replace(['M (part of expression)', 'metonymy'], 'M')\n",
        "\n",
        "scores = {}\n",
        "\n",
        "for cluster in clusters:\n",
        "  ARI = metrics.adjusted_rand_score(df[\"M/L\"], df[cluster])\n",
        "  Vmeasure = metrics.v_measure_score(df[\"M/L\"], df[cluster])\n",
        "  scores[cluster] = [ARI, Vmeasure]\n",
        "df_scores = pd.DataFrame(scores, index=['ARI', 'Vmeasure'])\n",
        "\n",
        "df_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb4c3a4f",
      "metadata": {},
      "source": [
        "## Dendrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "03079c52",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_dendrogram(model, **kwargs):\n",
        "    children = model.children_\n",
        "    distance = np.arange(children.shape[0])\n",
        "    no_of_observations = np.arange(2, children.shape[0]+2)\n",
        "    linkage_matrix = np.column_stack([children, distance, no_of_observations]).astype(float)\n",
        "    dendrogram(linkage_matrix, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d7039bc6",
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster=aggl_ward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5a514b5d",
      "metadata": {},
      "outputs": [],
      "source": [
        "labels=df['M/L'].values + ': ' + df['sentence'].values\n",
        "labels = [ '\\n'.join(wrap(l, 100)) for l in labels ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83b83f60",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 27))\n",
        "plt.title('Dendrogram \\'broeden\\', linkage = ward')\n",
        "\n",
        "plot_dendrogram(cluster, labels=labels, orientation='left', leaf_font_size=10)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fef31f7b",
      "metadata": {},
      "source": [
        "## Silhouette analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65b991a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "pca = PCA(n_components=3)\n",
        "components = pca.fit_transform(matrix_np)\n",
        "\n",
        "X = components\n",
        "\n",
        "range_n_clusters = [2, 3, 4, 5, 6]\n",
        "\n",
        "for n_clusters in range_n_clusters:\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.set_size_inches(18, 7)\n",
        "\n",
        "    ax1.set_xlim([-1, 1])\n",
        "\n",
        "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
        "\n",
        "    clusterer = KMeans(n_clusters=n_clusters, random_state=best_random_state)\n",
        "    cluster_labels = clusterer.fit(X).labels_\n",
        "\n",
        "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
        "    print(\n",
        "        \"For n_clusters =\",\n",
        "        n_clusters,\n",
        "        \"The average silhouette_score is :\",\n",
        "        silhouette_avg,\n",
        "    )\n",
        "\n",
        "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
        "\n",
        "    y_lower = 10\n",
        "    for i in range(n_clusters):\n",
        "    \n",
        "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
        "\n",
        "        ith_cluster_silhouette_values.sort()\n",
        "\n",
        "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "        y_upper = y_lower + size_cluster_i\n",
        "\n",
        "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
        "        ax1.fill_betweenx(\n",
        "            np.arange(y_lower, y_upper),\n",
        "            0,\n",
        "            ith_cluster_silhouette_values,\n",
        "            facecolor=color,\n",
        "            edgecolor=color,\n",
        "            alpha=0.7,\n",
        "        )\n",
        "\n",
        "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "\n",
        "        y_lower = y_upper + 10  \n",
        "\n",
        "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
        "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
        "    ax1.set_ylabel(\"Cluster label\")\n",
        "\n",
        "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
        "\n",
        "    ax1.set_yticks([])\n",
        "    ax1.set_xticks([-1, -0.8, -0.6, -0.4, -0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "\n",
        "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
        "    ax2.scatter(\n",
        "        X[:, 0], X[:, 1], marker=\".\", s=30, lw=0, alpha=0.7, c=colors, edgecolor=\"k\"\n",
        "    )\n",
        "\n",
        "    centers = clusterer.cluster_centers_\n",
        "  \n",
        "    ax2.scatter(\n",
        "        centers[:, 0],\n",
        "        centers[:, 1],\n",
        "        marker=\"o\",\n",
        "        c=\"white\",\n",
        "        alpha=1,\n",
        "        s=200,\n",
        "        edgecolor=\"k\",\n",
        "    )\n",
        "\n",
        "    for i, c in enumerate(centers):\n",
        "        ax2.scatter(c[0], c[1], marker=\"$%d$\" % i, alpha=1, s=50, edgecolor=\"k\")\n",
        "\n",
        "    ax2.set_title(\"The visualization of the clustered data.\")\n",
        "    ax2.set_xlabel(\"\")\n",
        "    ax2.set_ylabel(\"\")\n",
        "\n",
        "    plt.suptitle(\n",
        "        \"Silhouette analysis for KMeans clustering on sample data with n_clusters = %d\"\n",
        "        % n_clusters,\n",
        "        fontsize=14,\n",
        "        fontweight=\"bold\",\n",
        "    )\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17f10111",
      "metadata": {},
      "source": [
        "## k-means with more than two clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58c0214f",
      "metadata": {},
      "outputs": [],
      "source": [
        "kmeans_n = KMeans(n_clusters=4, n_init=\"auto\", random_state=best_random_state)\n",
        "kmeans_n = kmeans_n.fit(components)\n",
        "df[kmeans_n] = kmeans_n.labels_\n",
        "df_pca[kmeans_n] = kmeans_n.labels_\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fb098bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = px.scatter(df_pca, x='x', y='y', color='M/L',\n",
        "                 color_discrete_map={'M': 'red', 'L': 'blue'},\n",
        "                 symbol= kmeans_n,\n",
        "                 hover_data='sentence')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5072f2ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "ARI = metrics.adjusted_rand_score(df[\"M/L\"], df[kmeans_n])\n",
        "Vmeasure = metrics.v_measure_score(df[\"M/L\"], df[kmeans_n])\n",
        "scores[kmeans_n] = [ARI, Vmeasure]\n",
        "df_scores = pd.DataFrame(scores, index=['ARI', 'Vmeasure'])\n",
        "\n",
        "df_scores"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "e-CvbzZSG2tw"
      ],
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
